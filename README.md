# GenAI24â€‘NIST Textâ€‘toâ€‘Text Pipeline ğŸ“

Comprehensive solution for the **NISTÂ GenAI24 Textâ€‘toâ€‘Text** task.

---

## ğŸ“ Repository Layout

```
repo/Generator
â”œâ”€â”€ updated_a2c.py                # GeneratorÂ 1Â â€“ Actorâ€‘Critic RL
â”œâ”€â”€ generation_updated.ipynb      # GeneratorÂ 2Â â€“ Sampling & fluency
â”œâ”€â”€ xml_cleanup.ipynb
â””â”€â”€ outputs/
    â”œâ”€â”€ summaries.xml
repo/Discriminator
â”œâ”€â”€ Active Learning.ipynb         # DiscriminatorÂ 1Â â€“ GPTâ€‘assisted reviewer
â”œâ”€â”€ gen.py                        # DiscriminatorÂ 2Â â€“ RoBERTa train / test
â”œâ”€â”€ pred.py                       # Helper for gen.py inference
â”œâ”€â”€ discriminator_format.ipynb
â””â”€â”€ outputs/
    â””â”€â”€ results.csv               # AI/Human predictions
```

---

## âœ¨ At a Glance

| Category        | Module(s)                           | Highlights                                   |
|-----------------|-------------------------------------|----------------------------------------------|
| **GeneratorÂ 1** | `updated_a2c.py`                    | Actorâ€‘Critic RL, humanâ€‘like enhancements, XML writer |
| **GeneratorÂ 2** | `generation_updated.ipynb`          | Topâ€‘k / Topâ€‘p / Temp sampling exploration    |
| **DiscriminatorÂ 1** | `Active Learning.ipynb`         | GPTâ€‘4 review & manual filtering              |
| **DiscriminatorÂ 2** | `gen.py`Â (+Â `pred.py`)          | RoBERTa classifier (train & inference)       |

---

## 1Â Â·Â Generators

### ğŸ”¹ 1.1Â `updated_a2c.py` â€” Actorâ€‘Critic RL Generator

- Loads SGML topics & article files  
- Trains GPTâ€‘2 policy/value networks with **A2C**  
- Adds rhetorical devices, backâ€‘translation, paraphrasing  
- Uses internal RoBERTa reward for style compliance  
- Writes **`summaries.xml`** and **`results.csv`**

```bash
export OPENAI_API_KEY=sk-...
python updated_a2c.py
```

Key output files:

| File            | Purpose                |
|-----------------|------------------------|
| `summaries.xml` | NISTâ€‘formatted summaries |
| `results.csv`   | AI/Human flag per topic |
| `training.log`  | RL reward & loss        |

---

### ğŸ”¹ 1.2Â `generation_updated.ipynb` â€” Interactive Generator Notebook

| Technique                        | What it does                                                                                                                            |
| -------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------- |
| **Back-translation pipeline**    | Sends each draft summary through an intermediate language (e.g. French â†’ English) to introduce natural word order changes and idioms.   |
| **GPT-based paraphrasing**       | Calls `gpt-3.5-turbo` to rephrase sentences with configurable temperature and top-p.                                                    |
| **Role-aware rewriting**         | Extracts key **Subjects / Verbs / Objects** with spaCy, then injects them into prompts so the paraphrased text preserves factual roles. |
| **Rhetorical & hedge additions** | Adds analogies, hedge words (â€œperhapsâ€, â€œmightâ€) and temporal markers to mimic human narrative flow.                                    |


Open it in JupyterLab / VSÂ Code, run the cells sequentially, and adjust the cells marked **â€œğŸ”§ Parametersâ€** to experiment with different settings.

Use it for **exploratory runs, debugging and quick demos**, rather than headâ€‘less batch generation.
---

## 2Â Â·Â Discriminators

### ğŸ”¸ 2.1Â `ActiveÂ Learning.ipynb` â€” GPTâ€‘Assisted Reviewer

A notebook that:

1. Loads generator outputs  
2. Calls **GPTâ€‘4** for coherence, redundancy, toxicity scores  
3. Flags lowâ€‘quality summaries for human attention  
4. Optionally augments training data

Acts as a **semiâ€‘automatic discriminator**.

---

### ğŸ”¸ 2.2Â `gen.py` & `pred.py` â€” RoBERTa Classifier

#### Train

```bash
python gen.py   --mode train   --data_path ./train_data.csv   --model_save_path ./Roberta
```

`train_data.csv` columns: `text,label` (0Â =Â Human,Â 1Â =Â AI)

#### Infer

```bash
python gen.py   --mode test   --model_save_path ./Roberta   --input_directory ./txts   --results_file ./results.csv
```

Produces **`results.csv`** with confidence scores.

---

## âš™ï¸ Environment Setup

```bash
pip install torch transformers datasets evaluate scikit-learn openai             spacy nltk beautifulsoup4 rouge-score
python -m spacy download en_core_web_sm
python -m nltk.downloader punkt
```

---

## ğŸ“¤ Final Outputs

| File                 | Description                        |
|----------------------|------------------------------------|
| `outputs/summaries.xml` | Submission for NIST evaluation  |
| `outputs/results.csv`   | AI/Human discrimination results |
| `training.log`          | RL training trace               |
