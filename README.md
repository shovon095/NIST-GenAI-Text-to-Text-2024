# GenAI24â€‘NIST Textâ€‘toâ€‘Text Pipeline ğŸ“

Comprehensive solution for the **NISTÂ GenAI24 Textâ€‘toâ€‘Text** task.

---

## ğŸ“ Repository Layout

```
repo/Generator
â”œâ”€â”€ updated_a2c.py               # GeneratorÂ 1 â€“ Actor-Critic RL
â”œâ”€â”€ generation_updated.ipynb     # GeneratorÂ 2 â€“ Paraphrasing, Role-aware Back-Style
â”œâ”€â”€ xml_cleanup.ipynb            # Cleans and verifies NIST XML output
â””â”€â”€ outputs/
    â””â”€â”€ summaries.xml            # Final XML-formatted summaries for NIST

repo/Discriminator
â”œâ”€â”€ Active Learning.ipynb        # DiscriminatorÂ 1 â€“ Self-training with human in the loop using BERT and RoBERTa
â”œâ”€â”€ gen.py                       # DiscriminatorÂ 2 â€“ RoBERTa trainer & evaluator
â”œâ”€â”€ pred.py                      # Inference helper for gen.py
â”œâ”€â”€ discriminator_format.ipynb  # Visualization and format testing for discrimination outputs
â””â”€â”€ outputs/
    â””â”€â”€ results.csv              # AI/Human predictions
```


## âœ¨ At a Glance

| Category        | Module(s)                           | Highlights                                   |
|-----------------|-------------------------------------|----------------------------------------------|
| **GeneratorÂ 1** | `updated_a2c.py`                    | Actorâ€‘Critic RL, humanâ€‘like enhancements, XML writer |
| **GeneratorÂ 2** | `generation_updated.ipynb`          | Topâ€‘k / Topâ€‘p / Temp sampling exploration    |
| **DiscriminatorÂ 1** | `Active Learning.ipynb`         | GPTâ€‘4 review & manual filtering              |
| **DiscriminatorÂ 2** | `gen.py`Â (+Â `pred.py`)          | RoBERTa classifier (train & inference)       |

---

## 1Â Â·Â Generators

### ğŸ”¹ 1.1Â `updated_a2c.py` â€” Actorâ€‘Critic RL Generator

- Loads SGML topics & article files  
- Trains GPTâ€‘2 policy/value networks with **A2C**  
- Adds rhetorical devices, backâ€‘translation, paraphrasing  
- Uses internal RoBERTa reward for style compliance  
- Writes **`summaries.xml`** and **`results.csv`**

```bash
export OPENAI_API_KEY=sk-...
python updated_a2c.py
```

Key output files:

| File            | Purpose                |
|-----------------|------------------------|
| `summaries.xml` | NISTâ€‘formatted summaries |
| `results.csv`   | AI/Human flag per topic |
| `training.log`  | RL reward & loss        |

---

### ğŸ”¹ 1.2Â `generation_updated.ipynb` â€” Interactive Generator Notebook

| Technique                        | What it does                                                                                                                            |
| -------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------- |
| **Back-translation pipeline**    | Sends each draft summary through an intermediate language (e.g. French â†’ English) to introduce natural word order changes and idioms.   |
| **GPT-based paraphrasing**       | Calls `gpt-3.5-turbo` to rephrase sentences with configurable temperature and top-p.                                                    |
| **Role-aware rewriting**         | Extracts key **Subjects / Verbs / Objects** with spaCy, then injects them into prompts so the paraphrased text preserves factual roles. |
| **Rhetorical & hedge additions** | Adds analogies, hedge words (â€œperhapsâ€, â€œmightâ€) and temporal markers to mimic human narrative flow.                                    |


Open it in JupyterLab / VSÂ Code, run the cells sequentially, and adjust the cells marked **â€œğŸ”§ Parametersâ€** to experiment with different settings.

Use it for **exploratory runs, debugging and quick demos**, rather than headâ€‘less batch generation.
---

## 2Â Â·Â Discriminators

### ğŸ”¸ 2.1Â `Self training.ipynb` 

### ğŸ”¸ 2.1 `Active Learning.ipynb` â€” Manual Discriminator Feedback Interface

This notebook implements a **manual feedback loop** for reviewing and improving AI/Human classification results from multiple models (e.g., BERT and RoBERTa).

Features:

- Loads and aligns predictions from two different models  
- Displays **confidence scores and labels** for each summary  
- Highlights disagreements or low-confidence predictions  
- Provides an interface to **manually label or confirm** the final decision  
- Optionally records decisions to improve future training data

This tool helps simulate an **active learning process** where human reviewers guide the refinement of discriminator labels.

> No model training or inference is done here â€” it is a **human-in-the-loop evaluator** powered by precomputed model outputs.


---

### ğŸ”¸ 2.2Â `gen.py` & `pred.py` â€” RoBERTa Classifier

#### Train

```bash
python gen.py   --mode train   --data_path ./train_data.csv   --model_save_path ./Roberta
```

`train_data.csv` columns: `text,label` (0Â =Â Human,Â 1Â =Â AI)

#### Infer

```bash
python gen.py   --mode test   --model_save_path ./Roberta   --input_directory ./txts   --results_file ./results.csv
```

Produces **`results.csv`** with confidence scores.

---

## âš™ï¸ Environment Setup

```bash
pip install torch transformers datasets evaluate scikit-learn openai             spacy nltk beautifulsoup4 rouge-score
python -m spacy download en_core_web_sm
python -m nltk.downloader punkt
```

---

## ğŸ“¤ Final Outputs

| File                 | Description                        |
|----------------------|------------------------------------|
| `outputs/summaries.xml` | Submission for NIST evaluation  |
| `outputs/results.csv`   | AI/Human discrimination results |
| `training.log`          | RL training trace               |
